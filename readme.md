# UNet2D Conditional Model for Polygon Coloring

## ğŸ¯ Project Overview

This project implements a **Conditional UNet2D** model for polygon coloring, where the model learns to color grayscale polygon images based on text-based color conditions. This is a conditional image generation task that demonstrates the power of deep learning in understanding both visual patterns and textual conditions.

**Assignment**: Ayna ML Intern Role

## ğŸ—ï¸ Architecture

- **Model**: Conditional UNet2D with embedding layers
- **Input**: Grayscale polygon images (64x64) + color condition (text)
- **Output**: Colored polygon images (64x64, RGB)
- **Parameters**: 13.4M trainable parameters
- **Conditioning**: Text-to-embedding with spatial broadcasting

## ğŸ“Š Dataset

- **Training samples**: 56 images
- **Validation samples**: 5 images
- **Polygon types**: Circle, Square, Triangle, Hexagon, Pentagon, Octagon, Diamond, Star
- **Colors**: Blue, Cyan, Green, Magenta, Orange, Purple, Red, Yellow
- **Format**: PNG images, JSON metadata

## ğŸš€ Key Features

1. **Conditional Generation**: Colors polygons based on text conditions
2. **UNet Architecture**: Skip connections preserve spatial information
3. **Embedding System**: Converts text colors to numerical representations
4. **Progressive Training**: Learning rate scheduling and early stopping
5. **Model Persistence**: Automatic saving of best models
6. **Visualization**: Real-time training progress and results
7. **Inference Pipeline**: Easy-to-use prediction functions

## ğŸ“ˆ Performance

- **Best Validation Loss**: 0.1672 (MSE)
- **Training Epochs**: 55 (with early stopping)
- **Learning Rate**: 0.0001 â†’ 0.00005 (adaptive)
- **Training Time**: ~3 minutes on CPU

## ğŸ”§ Technical Implementation

### Model Architecture:
```
Conditional UNet2D:
â”œâ”€â”€ Condition Embedding (8 colors â†’ 64 dims)
â”œâ”€â”€ Encoder Path:
â”‚   â”œâ”€â”€ DoubleConv (3+64 â†’ 64)
â”‚   â”œâ”€â”€ Down (64 â†’ 128)
â”‚   â”œâ”€â”€ Down (128 â†’ 256)
â”‚   â”œâ”€â”€ Down (256 â†’ 512)
â”‚   â””â”€â”€ Down (512 â†’ 1024)
â””â”€â”€ Decoder Path:
    â”œâ”€â”€ Up (1024 â†’ 512) + skip
    â”œâ”€â”€ Up (512 â†’ 256) + skip
    â”œâ”€â”€ Up (256 â†’ 128) + skip
    â”œâ”€â”€ Up (128 â†’ 64) + skip
    â””â”€â”€ Output Conv (64 â†’ 3)
```

### Training Details:
- **Loss Function**: MSE Loss
- **Optimizer**: Adam
- **Batch Size**: 16
- **Data Augmentation**: Normalization, Resizing
- **Regularization**: Batch Normalization

## ğŸ“ Project Structure

```
â”œâ”€â”€ main.ipynb              # Complete implementation
â”œâ”€â”€ dataset/                # Training and validation data
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ inputs/         # Grayscale polygon images
â”‚   â”‚   â”œâ”€â”€ outputs/        # Colored target images
â”‚   â”‚   â””â”€â”€ data.json       # Metadata
â”‚   â””â”€â”€ validation/
â”œâ”€â”€ models/                 # Saved model checkpoints
â”‚   â”œâ”€â”€ best_model.pth     # Best model during training
â”‚   â””â”€â”€ final_model.pth    # Final model state
â””â”€â”€ readme.md              # This documentation
```

## ğŸ› ï¸ Requirements

```python
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.21.0
matplotlib>=3.5.0
pillow>=8.0.0
scikit-learn>=1.0.0
tqdm>=4.62.0
```

## ğŸš€ Usage

### Training:
```python
# Run all cells in main.ipynb
# The notebook contains complete implementation from data loading to evaluation
```

### Inference:
```python
from main import predict_single_image, load_best_model

# Load trained model
model, color_map = load_best_model('models/best_model.pth')

# Predict on new image
input_img, predicted_img = predict_single_image(
    model, 'path/to/polygon.png', 'red', color_map, transform
)
```

## ğŸ“Š Results

The model successfully learns to:
- âœ… Understand polygon shapes from grayscale inputs
- âœ… Interpret text-based color conditions
- âœ… Generate realistic colored outputs
- âœ… Maintain shape boundaries and details
- âœ… Generalize to unseen polygon-color combinations

### Training Curves:
- Training loss decreases steadily from 0.83 to 0.11
- Validation loss decreases from 0.96 to 0.17
- No overfitting observed with early stopping

### Visual Results:
The model produces high-quality colored polygons that match the specified color conditions while preserving the original shape geometry.

## ğŸ”¬ Future Improvements

1. **Dataset Expansion**: More polygon types and color variations
2. **Architecture Enhancements**: Attention mechanisms, residual connections
3. **Loss Functions**: Perceptual loss, adversarial training
4. **Advanced Conditioning**: Multiple conditions, texture generation
5. **Model Optimization**: Quantization, pruning for deployment

## ğŸ‘¨â€ğŸ’» Author

**Saikiranudayana**
- Ayna ML Intern Assignment
- Implementation Date: August 2025

## ğŸ“„ License

This project is created for educational and assignment purposes.